{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOphdU5DgfBt0lA/vVAwW/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/friedelj/AAI-510-TEAM-03/blob/main/JFriedel_IOT_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Joseph Friedel          AAI530 IOT               Assignment 3                          ------- 27 Jan. 2025"
      ],
      "metadata": {
        "id": "C1gFO-l5pjrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression Analysis and Prediction for IoT\n",
        "This notebook holds the Assignment 3.1 for Module 3 in AAI 530, Data Analytics and the Internet of Things. In this assignment, you will use linear\n",
        "regression to make predictions for simulated \"streaming\" data. The work that you do in this assignment will build on the linear regression predictions\n",
        "that you saw in your text book and in this week's lab session. Be sure to answer the analysis questions thoroughly, as this is a large part of the\n",
        "assignment for this week.\n",
        "\n",
        "General Assignment Instructions\n",
        "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it.\n",
        "                                                                                          \n",
        "\n",
        "One sign of mature code is conforming to a style guide. We recommend the Google Python Style Guide. If you use a different style guide, please include a\n",
        "cell with a link.\n",
        "\n",
        "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final\n",
        "submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential import statements and make sure that\n",
        "all such statements are moved into the designated cell.\n",
        "\n",
        "When you save your notebook as a pdf, make sure that all cell output is visible (even error messages) as this will aid your instructor in grading your\n",
        "work.\n",
        "\n",
        "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions\n",
        "to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. Make sure to answer every question marked with a Q:\n",
        "for full credit."
      ],
      "metadata": {
        "id": "5ZUiS3byp8kc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLJtbJRmpgUH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#suppress scientific notation in pandas\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use this cell to import additional libraries or define helper functions\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import mean_squared_error as mse"
      ],
      "metadata": {
        "id": "H7CHFle3qGH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and prepare your data\n",
        "We'll be using the cleaned household electric consumption dataset from Module 2 in this assignment. I recommend saving your dataset by running\n",
        "df.to_csv(\"filename\") at the end of the last assignment so that you don't have to re-do your cleaning steps. If you are not confident in your own\n",
        "cleaning steps, you may ask your instructor for a cleaned version of the data. You will not be graded on the cleaning steps in this assignment, but some\n",
        "functions may not work if you use the raw data.\n",
        "\n",
        "We need to turn our datetime column into a numeric value to be used as a variable in our linear regression. In the lab session, we created a new column\n",
        "of minutes and just incremented the value by 10 since we knew that the readings occurred every 10 minutes. In this dataset, we have readings every minute\n",
        ", but we might have some missing rows depending on how you cleaned your data. So instead we will convert our datetime column to something called\n",
        "unix/epoch time, which is the number of seconds since midnight on 1/1/1970.\n",
        "\n",
        "TODO: load your data and convert the datetime column into epoch/unix time"
      ],
      "metadata": {
        "id": "RGLdDwBdqLON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the original data into 'df_raw'\n",
        "df_raw = pd.read_csv(\"household_power_clean.csv\")\n",
        "\n",
        "# Clean the data and save it into 'df'\n",
        "df = df_raw.copy()\n",
        "\n",
        "# Remove rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Reset the index after cleaning\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Display the first few rows of the DataFrame to confirm it loaded correctly\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "bWjm8ga0qQ1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert datetime to epoch/unix time\n",
        "\n",
        "# Ensure the 'Datetime' column is in the correct datetime format\n",
        "df['Datetime'] = pd.to_datetime(df['Datetime'], format='%m/%d/%Y %H:%M')\n",
        "\n",
        "# Convert to Unix epoch time (seconds since Jan 1, 1970)\n",
        "df['UnixTime'] = df['Datetime'].astype('int64') // 10**9\n",
        "\n",
        "# Display the DataFrame to verify\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "OBKJ3kdFqX5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.tail(10))"
      ],
      "metadata": {
        "id": "8XJs9CX-qdxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting Global Active Power\n",
        "We will follow the code from the Chapter 9 in our textbook and the recorded lab session from this week to predict the Global Active Power (GAP) with\n",
        "linear regression.\n",
        "\n",
        "First we will create our x (time) and y (GAP) training variables, and then define our model parameters."
      ],
      "metadata": {
        "id": "2EpAxMwaqkJs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: What is ph? What is mu?\n",
        "\n",
        "A:PH is the \"points ahead\".  It's how many data points ahead you want to predict.  The further ahead, the harder it is to do in a linear regression.  \n",
        "Most likely your RMSE will increase as PH increases.\n",
        "\n",
        "MU is the Decay Facter, telling you the importance of every suceeding point in your prediction.  A MU of \"1\" provides no decay, and your whole dataset\n",
        "is used in the prediction.  If, for example mu=0.9, the 1st point is multiplied by 0.9^0, 2nd point 0.9^1, 3rd point 0.9^2, and so on.  So every\n",
        "suceeding point is less important in the predication, making the more recent data more relevant."
      ],
      "metadata": {
        "id": "6YhJeSsVqoUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Set the ph to be 5 minutes--consider the units that our time column is measured in."
      ],
      "metadata": {
        "id": "lhCwXGnoqst0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting Unix time and Global_active_power from the DataFrame\n",
        "ts = pd.DataFrame(df['UnixTime'])\n",
        "ys = pd.DataFrame(df['Global_active_power'])\n",
        "\n",
        "# Set prediction horizon (ph) to 5 minutes in seconds\n",
        "ph = 5 * 60  # 5 minutes converted to seconds\n",
        "\n",
        "# Determine the data resolution (difference between consecutive timestamps)\n",
        "time_resolution = ts.diff().dropna().iloc[0, 0]  # Assumes constant time intervals\n",
        "\n",
        "# Calculate ph_index as the number of time steps in the prediction horizon\n",
        "ph_index = int(ph / time_resolution)\n",
        "\n",
        "# Define mu\n",
        "mu = 0.9\n",
        "\n",
        "#let's limit the number of samples in our model to 5000 just for speed\n",
        "n_s = 5000\n",
        "\n",
        "# Arrays to hold predicted values\n",
        "tp_pred = np.zeros(n_s-1)\n",
        "yp_pred = np.zeros(n_s-1)\n",
        "\n",
        "print(\"ph (5 minutes in seconds):\", ph)\n",
        "print(\"Time resolution (seconds):\", time_resolution)\n",
        "print(\"ph_index (steps in 5 minutes):\", ph_index)"
      ],
      "metadata": {
        "id": "LPDRGYMRqwxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu = 0.9\n",
        "n_s = 5000\n",
        "\n",
        "# Weight of the first data point on the last prediction\n",
        "weight = mu**(n_s - 1)\n",
        "print(f\"Weight: {weight}\")"
      ],
      "metadata": {
        "id": "_btqVD9tq1xO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: With mu = 0.9, how much weight will our first data point have on the last (5000th) prediction in our limited dataset?\n",
        "\n",
        "A: Weight of the first data point on the 5000th prediction = mu^(n_s-1) ==0.9^4999 = ~0"
      ],
      "metadata": {
        "id": "CRn0trUjq5uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Following the code from Chapter 9 and the lab session, use linear regression to predict a rolling GAP for our dataset. Store these predictions in\n",
        "the tp_pred and yp_pred lists created above for visualization."
      ],
      "metadata": {
        "id": "-qfcbqKsq-i2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# At every iteration of the for loop a new data sample is acquired\n",
        "for i in range(2, n_s + 1):  # start out with 2 leading data points\n",
        "    # Get x and y data \"available\" for our prediction\n",
        "    ts_tmp=ts[0:i]\n",
        "    ys_tmp=ys[0:i]\n",
        "    ns = len(ys_tmp)\n",
        "\n",
        "    # Initialize weights with exponential decay\n",
        "    weights = np.ones(ns) * mu\n",
        "    for k in range(ns):\n",
        "        # Adjust weights to be downweighted according to their timestep away from our prediction\n",
        "        weights[k]=weights[k]**k\n",
        "    weights = np.flip(weights, 0)  # Flip to match order\n",
        "\n",
        "    # Perform linear regression on \"available\" data using the mu-adjusted weights\n",
        "    lm_tmp = LinearRegression()\n",
        "    model_tmp=lm_tmp.fit(ts_tmp, ys_tmp, sample_weight=weights)\n",
        "\n",
        "    # Store model coefficients (slope) and intercept to compute prediction\n",
        "    m_tmp = model_tmp.coef_   # Slope\n",
        "    q_tmp = model_tmp.intercept_  # Intercept\n",
        "\n",
        "    # Use ph to make the model prediction according to the prediction time\n",
        "    tp=ts.iloc[i-1,0]+ph\n",
        "    yp = m_tmp * tp + q_tmp  # Linear model prediction for the prediction time\n",
        "\n",
        "    # Store predictions for visualization\n",
        "    tp_pred[i - 2] = tp\n",
        "    yp_pred[i - 2] = yp"
      ],
      "metadata": {
        "id": "61xMiPHUrG4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's visualize the results from our model."
      ],
      "metadata": {
        "id": "sYFLBKEorLnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' %(mu, ph))\n",
        "ax.plot(tp_pred, yp_pred, label='Predicted Value')\n",
        "ax.plot(ts.iloc[0:n_s,0], ys.iloc[0:n_s,0], label='GAP data')\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "ouStJ4pHrQQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's difficult to tell how the model is performing from this plot.\n",
        "\n",
        "TODO: Modify the code above to visualize the first and last 200 datapoints/predictions (can be in separate charts) and compute the MSE for our\n",
        "predictions."
      ],
      "metadata": {
        "id": "d0NWp_qfrWuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot first 200 data points/predictions\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the first 200 points of the predicted values\n",
        "ax.plot(tp_pred[:200], yp_pred[:200], label='Predicted Value')\n",
        "\n",
        "# Plot only the first 200 points of the actual data\n",
        "ax.plot(ts.iloc[:200, 0], ys.iloc[:200, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "oIR6ycqKraVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to  plot a range of points\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Filter actual data within the specified time range\n",
        "mask_actual = (ts.iloc[:, 0] >= 1166291820) & (ts.iloc[:, 0] <= 1166292820)\n",
        "#mask_actual = (ts.iloc[:, 0] >=  1166291820) & (ts.iloc[:, 0] <= 1166292820)\n",
        "ax.plot(ts.iloc[mask_actual.values, 0], ys.iloc[mask_actual.values, 0], label='GAP data')\n",
        "\n",
        "# Filter predicted data within the same time range\n",
        "mask_pred = (tp_pred >= 1166291820) & (tp_pred <= 1166292820)\n",
        "#mask_pred = (tp_pred >=  1166291820) & (tp_pred <= 1166292820)\n",
        "ax.plot(tp_pred[mask_pred], yp_pred[mask_pred], label='Predicted Value')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "ouwyLMqErfG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot last 200 data points/predictions\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the last 200 points of the predicted values\n",
        "ax.plot(tp_pred[-200:], yp_pred[-200:], label='Predicted Value')\n",
        "\n",
        "# Plot only the last 200 points of the actual data\n",
        "ax.plot(ts.iloc[-200:, 0], ys.iloc[-200:, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "I9rGZUWNrkB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate MSE of predictions\n",
        "print(\"MSE is\", mse(ys['Global_active_power'][ph_index:5000+ph_index-1],yp_pred))"
      ],
      "metadata": {
        "id": "IhKdvFihrrjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: How did our model perform? What do you observe on the charts? Is there a difference between the early and the late predictions? What does the MSE\n",
        "tell you?\n",
        "\n",
        "A: You can't tell look at all the data points.  When you look at small sections like 200 points, the predictions look poor.\n",
        "Predictions are worse the end of the data.  In the full data plot, it looks like predictions are doing well or better in the middle of the data.\n",
        "The MSE seem low, or good, at 0.58.  "
      ],
      "metadata": {
        "id": "ur84CCqxrwgR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Re-run the prediction code with mu = 1 and mu = 0.01. Use the cells below to produce charts for the first and last 200 points and to compute the\n",
        "MSE for each of these sets of predictions."
      ],
      "metadata": {
        "id": "qHkSgsHBr0l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Re-run prediction code for mu = 1\n",
        "mu = 1\n",
        "\n",
        "# At every iteration of the for loop a new data sample is acquired\n",
        "for i in range(2, n_s + 1):  # start out with 2 leading data points\n",
        "    # Get x and y data \"available\" for our prediction\n",
        "    ts_tmp=ts[0:i]\n",
        "    ys_tmp=ys[0:i]\n",
        "    ns = len(ys_tmp)\n",
        "\n",
        "    # Initialize weights with exponential decay\n",
        "    weights = np.ones(ns) * mu\n",
        "    for k in range(ns):\n",
        "        # Adjust weights to be downweighted according to their timestep away from our prediction\n",
        "        weights[k]=weights[k]**k\n",
        "    weights = np.flip(weights, 0)  # Flip to match order\n",
        "\n",
        "    # Perform linear regression on \"available\" data using the mu-adjusted weights\n",
        "    lm_tmp = LinearRegression()\n",
        "    model_tmp=lm_tmp.fit(ts_tmp, ys_tmp, sample_weight=weights)\n",
        "\n",
        "    # Store model coefficients (slope) and intercept to compute prediction\n",
        "    m_tmp = model_tmp.coef_   # Slope\n",
        "    q_tmp = model_tmp.intercept_  # Intercept\n",
        "\n",
        "    # Use ph to make the model prediction according to the prediction time\n",
        "    tp=ts.iloc[i-1,0]+ph\n",
        "    yp = m_tmp * tp + q_tmp  # Linear model prediction for the prediction time\n",
        "\n",
        "    # Store predictions for visualization\n",
        "    tp_pred[i - 2] = tp\n",
        "    yp_pred[i - 2] = yp"
      ],
      "metadata": {
        "id": "VvORWdUHr4n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot first 200 data points/predictions for mu = 1\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the first 200 points of the predicted values\n",
        "ax.plot(tp_pred[:200], yp_pred[:200], label='Predicted Value')\n",
        "\n",
        "# Plot only the first 200 points of the actual data\n",
        "ax.plot(ts.iloc[:200, 0], ys.iloc[:200, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "6Nywc4Xvr9S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot last 200 data points/predictions for mu = 1\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the last 200 points of the predicted values\n",
        "ax.plot(tp_pred[-200:], yp_pred[-200:], label='Predicted Value')\n",
        "\n",
        "# Plot only the last 200 points of the actual data\n",
        "ax.plot(ts.iloc[-200:, 0], ys.iloc[-200:, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "DLHu_HY2sDs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate MSE of predictions for mu = 1\n",
        "print(\"MSE is\", mse(ys['Global_active_power'][ph_index:5000+ph_index-1],yp_pred))"
      ],
      "metadata": {
        "id": "5XrZMrGCsMHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Re-run prediction code for mu = 0.01\n",
        "mu = 0.01\n",
        "\n",
        "# At every iteration of the for loop a new data sample is acquired\n",
        "for i in range(2, n_s + 1):  # start out with 2 leading data points\n",
        "    # Get x and y data \"available\" for our prediction\n",
        "    ts_tmp=ts[0:i]\n",
        "    ys_tmp=ys[0:i]\n",
        "    ns = len(ys_tmp)\n",
        "\n",
        "    # Initialize weights with exponential decay\n",
        "    weights = np.ones(ns) * mu\n",
        "    for k in range(ns):\n",
        "        # Adjust weights to be downweighted according to their timestep away from our prediction\n",
        "        weights[k]=weights[k]**k\n",
        "    weights = np.flip(weights, 0)  # Flip to match order\n",
        "\n",
        "    # Perform linear regression on \"available\" data using the mu-adjusted weights\n",
        "    lm_tmp = LinearRegression()\n",
        "    model_tmp=lm_tmp.fit(ts_tmp, ys_tmp, sample_weight=weights)\n",
        "\n",
        "    # Store model coefficients (slope) and intercept to compute prediction\n",
        "    m_tmp = model_tmp.coef_   # Slope\n",
        "    q_tmp = model_tmp.intercept_  # Intercept\n",
        "\n",
        "    # Use ph to make the model prediction according to the prediction time\n",
        "    tp=ts.iloc[i-1,0]+ph\n",
        "    yp = m_tmp * tp + q_tmp  # Linear model prediction for the prediction time\n",
        "\n",
        "    # Store predictions for visualization\n",
        "    tp_pred[i - 2] = tp\n",
        "    yp_pred[i - 2] = yp"
      ],
      "metadata": {
        "id": "LL7aoMKisQqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot first 200 data points/predictions for mu = 0.01\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the first 200 points of the predicted values\n",
        "ax.plot(tp_pred[:200], yp_pred[:200], label='Predicted Value')\n",
        "\n",
        "# Plot only the first 200 points of the actual data\n",
        "ax.plot(ts.iloc[:200, 0], ys.iloc[:200, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "dyfoWdECsVUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot last 200 data points/predictions for mu = 0.01\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the last 200 points of the predicted values\n",
        "ax.plot(tp_pred[-200:], yp_pred[-200:], label='Predicted Value')\n",
        "\n",
        "# Plot only the last 200 points of the actual data\n",
        "ax.plot(ts.iloc[-200:, 0], ys.iloc[-200:, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "03YSrFxasbj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate MSE of predictions for mu = 0.01\n",
        "print(\"MSE is\", mse(ys['Global_active_power'][ph_index:5000+ph_index-1],yp_pred))"
      ],
      "metadata": {
        "id": "OWV3VUHfsfzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: How did our mu = 1 model perform? What do you observe on the charts? Is there a difference between the early and the late predictions? What does the\n",
        "MSE tell you?\n",
        "\n",
        "A: It performed worse in graph and in MSE.\n",
        "On the charts, less match between data and predicted.\n",
        "For both mu=0.9 and mu=1, the prediction strikes me as poor.  Early plotting is working.  The late plotting looks the same and incorrect.   \n",
        "I may have a coding error.\n",
        "The MSE increased sslightly for mu=1, so although the graphs were similar, the MSE showed performance deteriorated going from mu = 0.9 to mu = 1."
      ],
      "metadata": {
        "id": "eAaeU5NRskKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: How did our mu = 0.01 model perform? What do you observe on the charts? Is there a difference between the early and the late predictions? What does\n",
        "the MSE tell you?\n",
        "\n",
        "A: For mu=0.01, the early points graph looked better.  The late points graph looked the same, possibly because of a coding error.\n",
        "The MSE says the data is worse going to mu=0.01: from MSE=0.5 to 8!"
      ],
      "metadata": {
        "id": "TuesCpFysnsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: Which of these three models is the best? How do you know? Why does this make sense based on the mu parameter used?\n",
        "\n",
        "A:  Based on MSE mu=0.9 is the best.  It makes sense in that you wouls expect to have a mu sweet spot, somewhere between 0 and 1.\n",
        "But I think you'd have to more mu tests to find the optimum mu value."
      ],
      "metadata": {
        "id": "wizk7HP-srrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: What could we do to improve our model and/or make it more realistic and useful?\n",
        "\n",
        "A:  More data points, with a smaller delta between points (on the time axis).  Test more mu values to find yhe minimal MSE.  "
      ],
      "metadata": {
        "id": "s5HdciDTsvnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: Add voltage data as a second variable to our model and re-run the prediction code. Then visualize the first and last 200 points and compute the MSE"
      ],
      "metadata": {
        "id": "HwQxaQtvsz9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add voltage to the x-variables in our dataset\n",
        "\n",
        "# Extracting Unix time and Global_active_power from the DataFrame\n",
        "ts = pd.DataFrame(df['UnixTime'])\n",
        "ys = pd.DataFrame(df['Voltage'])\n",
        "\n",
        "# Set prediction horizon (ph) to 5 minutes in seconds\n",
        "ph = 5 * 60  # 5 minutes converted to seconds\n",
        "\n",
        "# Determine the data resolution (difference between consecutive timestamps)\n",
        "time_resolution = ts.diff().dropna().iloc[0, 0]  # Assumes constant time intervals\n",
        "\n",
        "# Calculate ph_index as the number of time steps in the prediction horizon\n",
        "ph_index = int(ph / time_resolution)\n",
        "\n",
        "# Define mu\n",
        "mu = 0.9\n",
        "\n",
        "#let's limit the number of samples in our model to 5000 just for speed\n",
        "n_s = 5000\n"
      ],
      "metadata": {
        "id": "CzAnZkQ9s5UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run the prediction code on your expanded dataset\n",
        "#make sure to adjust your yp prediction to include the coefficients from time AND voltage\n",
        "# Arrays to hold predicted values\n",
        "tp_pred = np.zeros(n_s-1)\n",
        "yp_pred = np.zeros(n_s-1)\n",
        "\n",
        "print(\"ph (5 minutes in seconds):\", ph)\n",
        "print(\"Time resolution (seconds):\", time_resolution)\n",
        "print(\"ph_index (steps in 5 minutes):\", ph_index)"
      ],
      "metadata": {
        "id": "FKN2iP_4s93g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot first 200 data points/predictions for the expanded dataset\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Voltage Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the first 200 points of the predicted values\n",
        "ax.plot(tp_pred[:200], yp_pred[:200], label='Predicted Value')\n",
        "\n",
        "# Plot only the first 200 points of the actual data\n",
        "ax.plot(ts.iloc[:200, 0], ys.iloc[:200, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('volts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "h-mYbz6VtCSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot last 200 data points/predictions for the expanded data\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Voltage Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the last 200 points of the predicted values\n",
        "ax.plot(tp_pred[-200:], yp_pred[-200:], label='Predicted Value')\n",
        "\n",
        "# Plot only the last 200 points of the actual data\n",
        "ax.plot(ts.iloc[-200:, 0], ys.iloc[-200:, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('volts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "2kkUi3y9tIDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate MSE of predictions for the expanded data\n",
        "print(\"MSE is\", mse(ys['Voltage'][ph_index:5000+ph_index-1],yp_pred))"
      ],
      "metadata": {
        "id": "fYndZ_pttNck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: How did the model performed when you added the voltage data? How does it compare to the models without it?\n",
        "\n",
        "A: Horribly.\n",
        "The model worked better for Power."
      ],
      "metadata": {
        "id": "fUSsouNltSMU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are lots of other ways that we could try to improve our model while still using linear regression.\n",
        "\n",
        "TODO: Choose one alternative model and re-run the prediction code. Some ideas include:\n",
        "\n",
        "Use a moving average as the response variable\n",
        "Make your prediction based on the time of day instead of as a continuous time series\n",
        "Use a moving window to limit your predictions instead of using a mu factor"
      ],
      "metadata": {
        "id": "ETfYYMXytWJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: Describe your alternative model and why it might improve your model\n",
        "\n",
        "A: I used the Moving Average method.  Moving average may be better at capturing short-term trends, while LR looks at the whole dataset.\n",
        "Moving average can be simplier to code, reducing the chaces of error.  Also moving averages, using averaging, may be better at noise reduction."
      ],
      "metadata": {
        "id": "je-X3EERtbws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create your alternative training data here\n",
        "# Extracting Unix time and Global_active_power from the DataFrame\n",
        "ts = pd.DataFrame(df['UnixTime'])\n",
        "ys = pd.DataFrame(df['Global_active_power'])\n",
        "\n",
        "# Setting prediction horizon (ph) to 5 minutes in seconds\n",
        "ph = 5 * 60  # 5 minutes converted to seconds\n",
        "\n",
        "# Determine the data resolution (difference between consecutive timestamps)\n",
        "time_resolution = ts.diff().dropna().iloc[0, 0]\n",
        "\n",
        "# Calculate ph_index as the number of time steps in the prediction horizon\n",
        "ph_index = int(ph / time_resolution)\n",
        "\n",
        "# Define the window size for the moving average\n",
        "window_size = 10\n",
        "\n",
        "#limiting the number of samples in model to 5000 just for speed\n",
        "n_s = 5000"
      ],
      "metadata": {
        "id": "Ax-hAkCPtfz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#re-run the prediction code here\n",
        "# Arrays to hold predicted values\n",
        "tp_pred = np.zeros(n_s-1)\n",
        "yp_pred = np.zeros(n_s-1)\n",
        "\n",
        "print(\"ph (5 minutes in seconds):\", ph)\n",
        "print(\"Time resolution (seconds):\", time_resolution)\n",
        "print(\"ph_index (steps in 5 minutes):\", ph_index)\n",
        "\n",
        "# At every iteration of the for loop, a new data sample is acquired\n",
        "for i in range(window_size, n_s + 1):  # start out with window_size leading data points\n",
        "    # Get available data for prediction\n",
        "    ts_tmp = ts[0:i]\n",
        "    ys_tmp = ys[0:i]\n",
        "\n",
        "    # Calculate the moving average of the last 'window_size' observations\n",
        "    moving_avg = ys_tmp.iloc[-window_size:].mean()  # Calculate average of last 'window_size' points\n",
        "\n",
        "    # Store the prediction for this time step\n",
        "    tp_pred[i - window_size] = ts.iloc[i - 1, 0] + ph  # Predicted time (in epoch) after the prediction horizon\n",
        "    yp_pred[i - window_size] = moving_avg  # Prediction is the moving average of the last window_size values"
      ],
      "metadata": {
        "id": "t8RfLf5ttz1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot first 200 data points/predictions for alternative model\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the first 200 points of the predicted values\n",
        "ax.plot(tp_pred[:200], yp_pred[:200], label='Predicted Value')\n",
        "\n",
        "# Plot only the first 200 points of the actual data\n",
        "ax.plot(ts.iloc[:200, 0], ys.iloc[:200, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "-DXphwTHt52-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot last 200 data points/predictions for alternative model\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "fig.suptitle('Global Active Power Prediction', fontsize=22, fontweight='bold')\n",
        "ax.set_title('mu = %g, ph=%g ' % (mu, ph))\n",
        "\n",
        "# Plot only the last 200 points of the predicted values\n",
        "ax.plot(tp_pred[-200:], yp_pred[-200:], label='Predicted Value')\n",
        "\n",
        "# Plot only the last 200 points of the actual data\n",
        "ax.plot(ts.iloc[-200:, 0], ys.iloc[-200:, 0], label='GAP data')\n",
        "\n",
        "ax.set_xlabel('time (epoch)')\n",
        "ax.set_ylabel('kilowatts')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "eSOdcCC9t97t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate MSE of predictions for alternative model\n",
        "print(\"MSE is\", mse(ys['Global_active_power'][ph_index:5000+ph_index-1],yp_pred))"
      ],
      "metadata": {
        "id": "DEyKmG7juJBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: Did your alternative model improve on our previous results? What else could you do to improve the model while still using linear regression?\n",
        "\n",
        "A: Yes.  The graphs looked similar but the MSE was cut by more than half: from 0.5 to 0.2.\n",
        "Again, more data points over a longer time period, and reduce  the time step size.  Run simulations to find the optimum mu and ph."
      ],
      "metadata": {
        "id": "BowZu6HxuMsH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's worth noting that the results we're getting int his assignment are based on a pretty short predictive horizon of 5 minutes. If we were to increase\n",
        "our predictive horizon, our results would likely be worse and there would be more room for optimizing and improving the predictions of our model."
      ],
      "metadata": {
        "id": "VqAz5PobuP2e"
      }
    }
  ]
}