{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPlikb9Q/Dl90A6RVyCtsq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/friedelj/AAI-510-TEAM-03/blob/main/JFriedel_Ethics_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "JFriedel            Ethics Class                    Assignment 3     18Mar 25"
      ],
      "metadata": {
        "id": "mcLC-p4QsGcW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvcFxZnGsDZ2"
      },
      "outputs": [],
      "source": [
        "pip install aif360"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "id": "vUnwv1xCsazW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, accuracy_score\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from lightgbm import LGBMClassifier\n",
        "from tqdm import tqdm\n",
        "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "GL5yeLj1se5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "fSKNdiNBsjrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "data=pd.read_csv(r\"C:\\Users\\josep\\credit_card_default_531v.1.csv\")"
      ],
      "metadata": {
        "id": "GsMhtSRgsoXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data preview\n",
        "data.head()"
      ],
      "metadata": {
        "id": "mFLOiRy5ss-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# structure and data types\n",
        "data.info()"
      ],
      "metadata": {
        "id": "OHKLfdB4syfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# missing value check\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing values:\\n\", missing_values)"
      ],
      "metadata": {
        "id": "FSH-UohOs318"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unique values in columns related to gender <- dataset uses 1 for male and 2 for female\n",
        "print(\"Unique values in 'SEX':\", data['SEX'].unique())"
      ],
      "metadata": {
        "id": "ENwNVkW1s5Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename only the target column for consistency\n",
        "data.rename(columns={\"default payment next month\": \"DEFAULT_NEXT_MONTH\"}, inplace=True)"
      ],
      "metadata": {
        "id": "iEWB8bdIs9Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encode SEX column: Male = 1, Female = 0 (already numeric, we are just replacing 2 with 0)\n",
        "data[\"SEX\"] = data[\"SEX\"].replace({2:0}) # Male = 1, Female = 0"
      ],
      "metadata": {
        "id": "GHtmXo_ptEWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EDUCATION: Map numbers to clear numeric categories for interpretability\n",
        "#Graduate = 1, University = 2, High School = 3, Other = 4\n",
        "data[\"EDUCATION\"] = data[\"EDUCATION\"].replace({\n",
        "    0: 4, # Map 0 to 'Other'\n",
        "    1: 1, # Graduate\n",
        "    2: 2, # University\n",
        "    3: 3, # High School\n",
        "    4: 4, # Other\n",
        "    5: 4, # Other\n",
        "    6: 4  # Other\n",
        "})"
      ],
      "metadata": {
        "id": "Xd4BGhs3tHft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MARRIAGE: Map numbers to clear numeric catergories for interpretability\n",
        "#Married = 1, Single =2, Other = 3\n",
        "data[\"MARRIAGE\"] = data[\"MARRIAGE\"].replace({\n",
        "    0: 3, # Map 0 to 'Other'\n",
        "    1: 1, # Married\n",
        "    2: 2, # Single\n",
        "    3: 3  # Other\n",
        "})"
      ],
      "metadata": {
        "id": "FUvAoyG-tMN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = [\"LIMIT_BAL\", \"SEX\", \"EDUCATION\", \"MARRIAGE\", \"AGE\", \"DEFAULT_NEXT_MONTH\"]\n",
        "data_subset = data[columns_to_keep]"
      ],
      "metadata": {
        "id": "j-c5lUGbtQ18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mean default rate by age\n",
        "age_default_prob = data.groupby(\"AGE\")[\"DEFAULT_NEXT_MONTH\"].mean()\n",
        "\n",
        "#plotting the probability of default by age\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.lineplot(x=age_default_prob.index, y=age_default_prob.values, marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
        "plt.title(\"Probability of Default by Age\", fontsize=16)\n",
        "plt.xlabel(\"Age\", fontsize=14)\n",
        "plt.ylabel(\"Probability of Default\", fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.grid(axis=\"both\", linestyle=\"--\", alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mmawd1T3tUN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bin ages into deciles\n",
        "age_bins = pd.qcut(data[\"AGE\"], q=10, duplicates=\"drop\")\n",
        "data[\"Age_Group\"] = age_bins\n",
        "\n",
        "# get range labels for deciles\n",
        "age_range_labels = [\n",
        "    f\"{int(interval.left)}-{int(interval.right)}\"\n",
        "    for interval in age_bins.cat.categories\n",
        "]\n",
        "\n",
        "# mapping these range labels back to the data\n",
        "data[\"Age_Group\"] = data[\"Age_Group\"].cat.rename_categories(age_range_labels)\n",
        "\n",
        "# calculate default probabilities for each age group\n",
        "age_default_prob = (\n",
        "    data.groupby(\"Age_Group\", observed=True)[\"DEFAULT_NEXT_MONTH\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"DEFAULT_NEXT_MONTH\": \"Default_Probability\"})\n",
        ")\n",
        "\n",
        "# plotting default probabilities\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(\n",
        "    data=age_default_prob,\n",
        "    x=\"Age_Group\",\n",
        "    y=\"Default_Probability\",\n",
        "    palette=\"coolwarm\",\n",
        "    edgecolor=\"black\",\n",
        ")\n",
        "plt.axhline(\n",
        "    y=age_default_prob[\"Default_Probability\"].mean(),\n",
        "    color=\"red\",\n",
        "    linestyle=\"--\",\n",
        "    linewidth=1.5,\n",
        "    label=\"Mean Default Probability\",\n",
        ")\n",
        "plt.title(\"Probability of Default by Age Group (Deciles)\", fontsize=16, fontweight=\"bold\")\n",
        "plt.xlabel(\"Age Range (Deciles)\", fontsize=14)\n",
        "plt.ylabel(\"Probability of Default\", fontsize=14)\n",
        "plt.xticks(rotation=45, fontsize=12)\n",
        "plt.yticks(rotation=12)\n",
        "plt.legend(fontsize=12, loc=\"upper right\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "STQ1kIIatYI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define privileged (26-47) and underpriveledged groups (21-25, 48+)\n",
        "data[\"Age_Group\"] = data[\"AGE\"].apply(\n",
        "lambda x: \"Priveledged (Ages 26-47)\" if 26 <= x <= 47 else \"Underprivedged (Ages 21-25, 48+)\"\n",
        ")\n",
        "\n",
        "# calculate default probabilities for each group\n",
        "age_group_default_prob = (\n",
        "    data.groupby(\"Age_Group\", observed=True)[\"DEFAULT_NEXT_MONTH\"]\n",
        "    .mean()\n",
        "    .reset_index()\n",
        "    .rename(columns={\"DEFAULT_NEXT_MONTH\": \"Default_Probability\"})\n",
        ")\n",
        "\n",
        "#plot default probsbilities with a regression line\n",
        "plt.figure(figsize=(12, 7))\n",
        "sns.barplot(\n",
        "    data=age_group_default_prob,\n",
        "    x=\"Age_Group\",\n",
        "    y=\"Default_Probability\",\n",
        "palette=\"coolwarm\",\n",
        "edgecolor=\"black\"\n",
        ")\n",
        "\n",
        "sns.regplot(\n",
        "    x=np.arange(len(age_group_default_prob)),\n",
        "    y=age_group_default_prob[\"Default_Probability\"],\n",
        "    scatter=False, color=\"blue\", label=\"Regression Line\", ci=None\n",
        ")\n",
        "\n",
        "plt.axhline(\n",
        "    y=age_group_default_prob[\"Default_Probability\"].mean(),\n",
        "    color=\"red\",\n",
        "    linestyle=\"--\",\n",
        "    linewidth=1.5,\n",
        "    label=\"Mean Default Probability\"\n",
        ")\n",
        "\n",
        "plt.title(\"Probability of Default by Age Group\", fontsize=16, fontweight=\"bold\")\n",
        "plt.xlabel(\"Age Group\", fontsize=14)\n",
        "plt.ylabel(\"Probability of Default\", fontsize=14)\n",
        "plt.xticks(ticks=np.arange(len(age_group_default_prob)), labels=age_group_default_prob[\"Age_Group\"], fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.legend(fontsize=12, loc=\"upper right\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b8XeG5SPtjyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define Age_Group for priveleged and underpriveledged groups\n",
        "youngest_quartile = data[\"AGE\"].quantile(0.25)\n",
        "oldest_quartile = data[\"AGE\"].quantile(0.75)\n",
        "\n",
        "data[\"Age_Group\"] = data[\"AGE\"].apply(\n",
        "    lambda x: 1 if youngest_quartile < x <= oldest_quartile else 0\n",
        ") # 1 for Privilaged  0 for Underprivilaged\n",
        "\n",
        "# double checking the gender encoding\n",
        "data[\"Gender_Label\"] = data[\"SEX\"].replace({1: \"Male\", 0: \"Female\"})\n",
        "\n",
        "# underpriveledged group\n",
        "underpriviledged_group = data[data[\"Age_Group\"] == 0]\n",
        "\n",
        "# default probabilities for males and females in the underpriviledged group\n",
        "default_rates_underpriviledged = (\n",
        "    underpriviledged_group.groupby(\"Gender_Label\")[\"DEFAULT_NEXT_MONTH\"].mean() * 100\n",
        ")\n",
        "\n",
        "#bar plot for default rates in the underpriviledged group xgender\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    x=default_rates_underpriviledged.index,\n",
        "    y=default_rates_underpriviledged.values,\n",
        "    palette=[\"orange\", \"green\"],\n",
        "    edgecolor=\"black\"\n",
        ")\n",
        "\n",
        "plt.title(\"Default Rates for Underprivileged Group by Gender\", fontsize=16, fontweight=\"bold\")\n",
        "plt.ylabel(\"Default Rate (%)\", fontsize=14)\n",
        "plt.xlabel(\"Gender\", fontsize=14)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u3DV9z0PtoOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##QUANTIFYING DATASET BIAS"
      ],
      "metadata": {
        "id": "TlbznmI4twZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set seed\n",
        "rand = 531\n",
        "np.random.seed(rand)\n",
        "\n",
        "# defining our target and features\n",
        "y = data[\"DEFAULT_NEXT_MONTH\"]\n",
        "X = data.drop([\"DEFAULT_NEXT_MONTH\"], axis=1).copy()\n",
        "\n",
        "# splitting into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=rand)"
      ],
      "metadata": {
        "id": "veO-9LY6ttC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# priviledged and underpriviledged Groups for Age\n",
        "X_train[\"Age_Group\"] = X_train[\"AGE\"].apply(lambda x: 1 if 26 <= x <= 47 else 0)\n",
        "X_test[\"Age_Group\"] = X_test[\"AGE\"].apply(lambda x: 1 if 26 <= x <= 47 else 0)"
      ],
      "metadata": {
        "id": "8wiUjI0qt3ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gender\n",
        "X_train[\"Gender_Label\"] = X_train[\"SEX\"].replace({1: 1, 0: 0}) # female 0, male 1\n",
        "X_test[\"Gender_Label\"] = X_test[\"SEX\"].replace({1: 1, 0: 0})"
      ],
      "metadata": {
        "id": "5hKpvzQEt6aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combie X_train and y_train for BinaryLabelDataset\n",
        "train_ds = BinaryLabelDataset(\n",
        "    df=X_train.join(y_train),\n",
        "    label_names=[\"DEFAULT_NEXT_MONTH\"],\n",
        "    protected_attribute_names=[\"Age_Group\", \"Gender_Label\"],\n",
        "    favorable_label=0, # 0 did not default\n",
        "    unfavorable_label=1 # 1 defaulted\n",
        ")"
      ],
      "metadata": {
        "id": "6MJgogPEt9Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining our groups, remeber- priviledged is 26-47 and underpriviledged is 21-25 & 48+\n",
        "privileged_groups = [{\"Age_Group\": 1}]\n",
        "unprivileged_groups = [{\"Age_Group\": 0}]"
      ],
      "metadata": {
        "id": "4aYrNh8GuANc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then, compute our metrics for training data\n",
        "metrics_train_ds = BinaryLabelDatasetMetric(\n",
        "    train_ds,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")"
      ],
      "metadata": {
        "id": "LBekGiP-uDFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print results from training data\n",
        "print(\"Training Data Metrics:\")\n",
        "print(f\"Statistical Parity Difference (SPD): {metrics_train_ds.statistical_parity_difference():.4f}\")\n",
        "print(f\"Disparate Impact (DI): {metrics_train_ds.disparate_impact():.4f}\")\n",
        "print(f\"Smoothed Empirical Differential Fairness (SEDF): {metrics_train_ds.smoothed_empirical_differential_fairness():.4f}\")"
      ],
      "metadata": {
        "id": "fHbveIZLuGF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## QUANTIFYING MODEL BIAS"
      ],
      "metadata": {
        "id": "tPd3KXG1uM28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_params = {\n",
        "    'learning_rate': 0.4,\n",
        "    'reg_alpha': 21,\n",
        "    'reg_lambda':1,\n",
        "    'scale_pos_weight': 1.8\n",
        "}\n",
        "\n",
        "lgb_base_model = LGBMClassifier(random_seed=531, max_depth=6, num_leaves=33, **lgb_params)\n",
        "lgb_base_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "iY41uBSruJ0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model\n",
        "y_pred_test = lgb_base_model.predict(X_test)\n",
        "y_pred_prob_test = lgb_base_model.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "gKl33KMpuRG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_test)\n",
        "precision = precision_score(y_test, y_pred_test)\n",
        "recall = recall_score(y_test, y_pred_test)\n",
        "f1 = f1_score(y_test, y_pred_test)\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob_test)"
      ],
      "metadata": {
        "id": "BVTquhNJuVoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print results\n",
        "print(f\"Accuracy (Test): {accuracy:.4f}\")\n",
        "print(f\"Precision (Test): {precision:.4f}\")\n",
        "print(f\"Recall (Test): {recall:.4f}\")\n",
        "print(f\"F1-Score (Test): {f1:.4f}\")\n",
        "print(f\"ROC-AUC (Test): {roc_auc:.4f}\")"
      ],
      "metadata": {
        "id": "3_v897F9uYtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate model\n",
        "y_pred_train = lgb_base_model.predict(X_train)\n",
        "y_pred_prob_train = lgb_base_model.predict_proba(X_train)[:, 1]"
      ],
      "metadata": {
        "id": "XyWvmuLbudd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# performance metrics\n",
        "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "precision_train = precision_score(y_train, y_pred_train)\n",
        "recall_train = recall_score(y_train, y_pred_train)\n",
        "f1_train = f1_score(y_train, y_pred_train)\n",
        "roc_auc_train = roc_auc_score(y_train, y_pred_prob_train)"
      ],
      "metadata": {
        "id": "eNSBfV9due6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy (Train): {accuracy_train:.4f}\")\n",
        "print(f\"Precision (Train): {precision_train:.4f}\")\n",
        "print(f\"Recall (Train): {recall_train:.4f}\")\n",
        "print(f\"F1-Score (Train): {f1_train:.4f}\")\n",
        "print(f\"ROC-AUC (Train): {roc_auc_train:.4f}\")"
      ],
      "metadata": {
        "id": "q4kCFpvyujps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FAIRNESS METRICS"
      ],
      "metadata": {
        "id": "D0XswH_guqX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# passing test_ds into BinaryLabelDataset\n",
        "test_ds = BinaryLabelDataset(\n",
        "    df=X_test.join(y_test),\n",
        "    label_names=[\"DEFAULT_NEXT_MONTH\"],\n",
        "    protected_attribute_names=[\"Age_Group\", \"Gender_Label\"],\n",
        "    favorable_label=0, # 0 no default\n",
        "    unfavorable_label=1 # 1 defaulted\n",
        ")"
      ],
      "metadata": {
        "id": "IwGCcWM_unB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add predictions and scores to the test dataset for our fairness metrics\n",
        "test_pred_ds = test_ds.copy(deepcopy=True)\n",
        "test_pred_ds.labels = y_pred_test.reshape(-1, 1)\n",
        "test_pred_ds.scores = y_pred_prob_test.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "tdUocI7wuuu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Fairness Metrics\n",
        "metrics_test_cls = ClassificationMetric(\n",
        "    test_ds,\n",
        "    test_pred_ds,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")"
      ],
      "metadata": {
        "id": "JGcJ5TnOuy3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Fairness Metrics\n",
        "print(\"\\nFairness Metrics on Test Data:\")\n",
        "print(f\"Statistical Parity Difference (SPD): {metrics_test_cls.statistical_parity_difference():.4f}\")\n",
        "print(f\"Disparate Impact (DI): {metrics_test_cls.disparate_impact():.4f}\")\n",
        "print(f\"Smoothed Empiracal Differential Fairness (SEDF): {metrics_train_ds.smoothed_empirical_differential_fairness():.4f}\")"
      ],
      "metadata": {
        "id": "1jNoII9ou2HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mitigating Bias"
      ],
      "metadata": {
        "id": "UGnEm2WCu88M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reweighting Method"
      ],
      "metadata": {
        "id": "fLXFfkZFvAmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# apply reweighing\n",
        "reweighter = Reweighing(\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")\n",
        "\n",
        "reweighter.fit(train_ds)\n",
        "train_rw_ds = reweighter.transform(train_ds)"
      ],
      "metadata": {
        "id": "Un7n26x-u7TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics for the reweighted training dataset\n",
        "metrics_train_rw_ds = BinaryLabelDatasetMetric(\n",
        "    train_rw_ds,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")"
      ],
      "metadata": {
        "id": "eDjvhZzxvIF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics for the reweighted training dataset\n",
        "metrics_train_rw_ds = BinaryLabelDatasetMetric(\n",
        "    train_rw_ds,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")"
      ],
      "metadata": {
        "id": "nEg2SiSXvL30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics for the reweighted training dataset\n",
        "metrics_train_rw_ds = BinaryLabelDatasetMetric(\n",
        "    train_rw_ds,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")"
      ],
      "metadata": {
        "id": "_QM8bqyAvPYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training LightGPM on the Reweighted Dataset"
      ],
      "metadata": {
        "id": "cGrZ6L0GvWTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train LightGbM\n",
        "lgb_rw_model = LGBMClassifier(\n",
        "    random_state=531,\n",
        "    max_depth=6,\n",
        "    num_leaves=33,\n",
        "    **lgb_params\n",
        ")"
      ],
      "metadata": {
        "id": "p1ME5xAOvTKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use reweighted dataset's instance weights\n",
        "lgb_rw_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    sample_weight=train_rw_ds.instance_weights\n",
        ")"
      ],
      "metadata": {
        "id": "VEg11Y-zvbbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate performance metrics\n",
        "y_pred_test_rw = lgb_rw_model.predict(X_test)\n",
        "y_pred_prob_test_rw = lgb_rw_model.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "rrf3fsihve2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Performance Metrics\n",
        "accuracy_rw = accuracy_score(y_test, y_pred_test_rw)\n",
        "precision_rw = precision_score(y_test, y_pred_test_rw)\n",
        "recall_rw = recall_score(y_test, y_pred_test_rw)\n",
        "f1_rw = f1_score(y_test, y_pred_test_rw)\n",
        "roc_auc_rw = roc_auc_score(y_test, y_pred_prob_test_rw)"
      ],
      "metadata": {
        "id": "-jOILxc2vnA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPerformance Metrics for Reweighted Model:\")\n",
        "print(f\"Accuracy (Test): {accuracy_rw:.4f}\")\n",
        "print(f\"Precision (Test): {precision_rw:.4f}\")\n",
        "print(f\"Recall (Test): {recall_rw:.4f}\")\n",
        "print(f\"F1-Score (Test): {f1_rw:.4f}\")\n",
        "print(f\"ROC-AUC (Test): {roc_auc_rw:.4f}\")"
      ],
      "metadata": {
        "id": "zbMBTAcKvqEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Fairness Metrics & Add Predictions/Scors to Test DS\n",
        "test_pred_rw_ds = test_ds.copy(deepcopy=True)\n",
        "test_pred_rw_ds.labels = y_pred_test_rw.reshape(-1, 1)\n",
        "test_pred_rw_ds.scores = y_pred_prob_test_rw.reshape(-1,1)"
      ],
      "metadata": {
        "id": "SsVg0JtKvs9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fairness Metrics for the ReWeighted Model\n",
        "metrics_test_rw_cls = ClassificationMetric(\n",
        "    test_ds,\n",
        "    test_pred_rw_ds,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")"
      ],
      "metadata": {
        "id": "PP5xbdiVvxUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Fairness Metrics\n",
        "print(\"\\nFairness Metrics for Reweighted Model on Test Data:\")\n",
        "print(f\"Statistical Parity Difference (SPD): {metrics_test_rw_cls.statistical_parity_difference():.4f}\")\n",
        "print(f\"Disparate Impact (DI): {metrics_test_rw_cls.disparate_impact():.4f}\")\n",
        "print(f\"Equal Opportunity Difference (EOD): {metrics_test_rw_cls.equal_opportunity_difference():.4f}\")\n",
        "print(f\"Average Odds Difference (AOD): {metrics_test_rw_cls.average_odds_difference():.4f}\")\n",
        "print(f\"Differential Fairness Bias Amplification (DFBA): {metrics_test_rw_cls.differential_fairness_bias_amplification():.4f}\")"
      ],
      "metadata": {
        "id": "AvAMh3jnv0Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DISPARATE IMPACT REMOVER (DIR)"
      ],
      "metadata": {
        "id": "GtNb90FYv5Dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the levels of repair\n",
        "levels = np.hstack([np.linspace(0., 0.1, 41), np.linspace(0.2, 1, 9)])\n",
        "protected_index = train_ds.feature_names.index(\"Age_Group\")"
      ],
      "metadata": {
        "id": "NdOJzuK8v8eV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize variables to track the best repair level\n",
        "di = np.array([])  # Collect Disparate Impact for all levels\n",
        "train_dir_ds = None\n",
        "test_dir_ds = None\n",
        "X_train_dir = None\n",
        "X_test_dir = None\n",
        "lgb_dir_model = None"
      ],
      "metadata": {
        "id": "5UaLSu64v_sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install BlackBoxAuditing"
      ],
      "metadata": {
        "id": "ngukXhU0wDkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "oAgSJwebwGeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through repair levels\n",
        "for level in tqdm(levels):\n",
        "    #apply DIR at the current repair level\n",
        "    di_remover = DisparateImpactRemover(repair_level=level)\n",
        "    train_dir_ds_i = di_remover.fit_transform(train_ds)\n",
        "    test_dir_ds_i = di_remover.fit_transform(test_ds)\n",
        "\n",
        "    #remove protected attribute from features\n",
        "    X_train_dir_i = np.delete(train_dir_ds_i.features, protected_index, axis=1)\n",
        "    X_test_dir_i = np.delete(test_dir_ds_i.features, protected_index, axis=1)\n",
        "\n",
        "    #train LightGBM model on the repaired daataset\n",
        "    lgb_dir_model_i = lgb.LGBMClassifier(\n",
        "        random_state=rand, max_depth=5, num_leaves=33, verbose=-1, **lgb_params\n",
        "    )\n",
        "    lgb_dir_model_i.fit(X_train_dir_i, train_dir_ds_i.labels)\n",
        "\n",
        "    # predict on the repaired dataset\n",
        "    test_dir_ds_pred_i = test_dir_ds_i.copy()\n",
        "    test_dir_ds_pred_i.labels = lgb_dir_model_i.predict(X_test_dir_i)\n",
        "\n",
        "    # fairness metrics\n",
        "    metrics_test_dir_ds = BinaryLabelDatasetMetric(\n",
        "        test_dir_ds_pred_i,\n",
        "        unprivileged_groups=unprivileged_groups,\n",
        "        privileged_groups=privileged_groups\n",
        "    )\n",
        "    di_i = metrics_test_dir_ds.disparate_impact()\n",
        "\n",
        "    # track and print DI for this level\n",
        "    print(F\"Repair Level: {level:.2f}, Disparate Impact: {di_i:.4f}\")\n",
        "\n",
        "    #update thebest results if this level is closest to DI=1\n",
        "    if (di.shape[0] == 0) or (np.min(np.abs(di -1)) >= abs(di_i -1)):\n",
        "        train_dir_ds = train_dir_ds_i\n",
        "        test_dir_ds = test_dir_ds_i\n",
        "        X_train_dir = X_train_dir_i\n",
        "        X_test_dir = X_test_dir_i\n",
        "        lgb_dir_model = lgb_dir_model_i\n",
        "\n",
        "    # append to DI List\n",
        "    di = np.append(di, di_i)"
      ],
      "metadata": {
        "id": "S2jlhW2pwJ_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Disparate Impact across repair levels\n",
        "di = di[:len(levels)]"
      ],
      "metadata": {
        "id": "tLR5cKZowQsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close(plt.gcf())"
      ],
      "metadata": {
        "id": "Ypmf0SRHwTHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Seaborn style for better visuals\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(11, 6))"
      ],
      "metadata": {
        "id": "gtelvfnQwV_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Disparate Impact (DI) against repair levels\n",
        "plt.plot(levels, di, marker=\"x\", linestyle=\"-\", color=\"green\", label=\"Disparate Impact\")"
      ],
      "metadata": {
        "id": "OHKWlpIJwYzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add labels, title, and legend\n",
        "plt.ylabel(\"Disparate Impact (DI)\", fontsize=14)\n",
        "plt.xlabel(\"Repair Level\", fontsize=14)\n",
        "plt.title(\"Disparate Impact Across Repair Levels\", fontsize=16)\n",
        "plt.legend(fontsize=12)"
      ],
      "metadata": {
        "id": "l45jd5NUwcct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show grid for readability\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "7c5OfHN5wfUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nSWEfoVqwiO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "display(plt.gcf())"
      ],
      "metadata": {
        "id": "YD0LqgI-wlfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the best repair level and its corresponding disparate impact\n",
        "best_level = levels[np.argmin(np.abs(di - 1))]\n",
        "print(f\"Best Repair Level: {best_level:.2f}\")\n",
        "print(f\"Disparate Impact at Best Level: {di[np.argmin(np.abs(di - 1))]:.4f}\")"
      ],
      "metadata": {
        "id": "lPrYR1UywoXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on the modified test data (from DIR)\n",
        "y_pred_test_dir = lgb_dir_model.predict(X_test_dir)\n",
        "y_pred_prob_test_dir = lgb_dir_model.predict_proba(X_test_dir)[:, 1]"
      ],
      "metadata": {
        "id": "pWDNkJw8wr0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute Performance Metrics on the test data\n",
        "accuracy_test_dir = accuracy_score(y_test, y_pred_test_dir)\n",
        "precision_test_dir = precision_score(y_test, y_pred_test_dir)\n",
        "recall_test_dir = recall_score(y_test, y_pred_test_dir)\n",
        "f1_test_dir = f1_score(y_test, y_pred_test_dir)\n",
        "roc_auc_test_dir = roc_auc_score(y_test, y_pred_prob_test_dir)"
      ],
      "metadata": {
        "id": "2GbYg_JRwumd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Performance Metrics\n",
        "print(f\"Accuracy: {accuracy_test_dir:.4f}\")\n",
        "print(f\"Precision: {precision_test_dir:.4f}\")\n",
        "print(f\"Recall: {recall_test_dir:.4f}\")\n",
        "print(f\"F1-Score: {f1_test_dir:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_test_dir:.4f}\")"
      ],
      "metadata": {
        "id": "tUKNrjWWwz0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions and scores to the BinaryLabelDataset for our Fairness Metrics\n",
        "test_dir_ds_pred = test_dir_ds.copy(deepcopy=True)\n",
        "test_dir_ds_pred.labels = y_pred_test_dir.reshape(-1, 1)\n",
        "test_dir_ds_pred.scores = y_pred_prob_test_dir.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "pC_9Y87-w28U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fairness Metrics\n",
        "metrics_test_dir_cls = ClassificationMetric(\n",
        "    test_dir_ds,\n",
        "    test_dir_ds_pred,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")"
      ],
      "metadata": {
        "id": "hL97tOdUw5xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Fairness Metrics\n",
        "print(\"\\nFairness Metrics on Test Data (DIR) Applied):\")\n",
        "print(f\"Statistical Parity Difference (SPD): {metrics_test_dir_cls.statistical_parity_difference():.4f}\")\n",
        "print(f\"Disparate Impact (DI): {metrics_test_dir_cls.disparate_impact():.4f}\")\n",
        "print(f\"Equal Opportunity Difference (EOD): {metrics_test_dir_cls.equal_opportunity_difference():.4f}\")\n",
        "print(f\"Avverage Odds Difference (AOD): {metrics_test_dir_cls.average_odds_difference():.4f}\")\n",
        "print(f\"Differential Fairness Bias Amplification( DFBA): {metrics_test_dir_cls.differential_fairness_bias_amplification():.4f}\")"
      ],
      "metadata": {
        "id": "PWISCXLQw94t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison of Performance Metrics\n",
        "print(\"\\nComparison of Performance Metrics Across Models:\")\n",
        "print(f\"{'Metric':<15}{'Original':<15}{'Reweighted':<15}{'DIR Applied':<15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Accuracy':<15}{accuracy:<15.4f}{accuracy_rw:<15.4f}{accuracy_test_dir:<15.4f}\")\n",
        "print(f\"{'Precision':<15}{precision:<15.4f}{precision_rw:<15.4f}{precision_test_dir:<15.4f}\")\n",
        "print(f\"{'Recall':<15}{recall:<15.4f}{recall_rw:<15.4f}{recall_test_dir:<15.4f}\")\n",
        "print(f\"{'F1-Score':<15}{f1:<15.4f}{f1_rw:<15.4f}{f1_test_dir:<15.4f}\")\n",
        "print(f\"{'ROC-AUC':<15}{roc_auc:<15.4f}{roc_auc_rw:<15.4f}{roc_auc_test_dir:<15.4f}\")"
      ],
      "metadata": {
        "id": "lXmcVvsbxBmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison of Fairness Metrics\n",
        "print(\"\\nComparison of Fairness Metrics Across Models:\")\n",
        "print(f\"{'Metric':<15}{'Original':<15}{'Reweighted':<15}{'DIR Applied':<15}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'SPD':<15}{metrics_test_cls.statistical_parity_difference():<15.4f}{metrics_test_rw_cls.statistical_parity_difference():<15.4f}{metrics_test_dir_cls.statistical_parity_difference():<15.4f}\")\n",
        "print(f\"{'DI':<15}{metrics_test_cls.disparate_impact():<15.4f}{metrics_test_rw_cls.disparate_impact():<15.4f}{metrics_test_dir_cls.disparate_impact():<15.4f}\")\n",
        "print(f\"{'SEDF':<15}{metrics_test_cls.smoothed_empirical_differential_fairness():<15.4f}{metrics_test_rw_cls.smoothed_empirical_differential_fairness():<15.4f}{metrics_test_dir_cls.smoothed_empirical_differential_fairness():<15.4f}\")"
      ],
      "metadata": {
        "id": "ljEstxrxxG01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1: Experimentation with the DIR (assignment output should be included in 3.1 Exercise Document"
      ],
      "metadata": {
        "id": "IzOhXndBxO4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1.1a."
      ],
      "metadata": {
        "id": "kszqsCKOxSx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finer granularity\n",
        "levels = np.hstack([np.linspace(0., 0.1, 81), np.linspace(0.2, 1, 20)])\n",
        "protected_index = train_ds.feature_names.index(\"Age_Group\")"
      ],
      "metadata": {
        "id": "l-I7ds-wxMuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize variables to track the best repair level\n",
        "di = np.array([])  # Collect Disparate Impact for all levels\n",
        "train_dir_ds = None\n",
        "test_dir_ds = None\n",
        "X_train_dir = None\n",
        "X_test_dir = None\n",
        "lgb_dir_model = None"
      ],
      "metadata": {
        "id": "aBAGO0QRxaeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through repair levels\n",
        "for level in tqdm(levels):\n",
        "    #apply DIR at the current repair level\n",
        "    di_remover = DisparateImpactRemover(repair_level=level)\n",
        "    train_dir_ds_i = di_remover.fit_transform(train_ds)\n",
        "    test_dir_ds_i = di_remover.fit_transform(test_ds)\n",
        "\n",
        "    #remove protected attribute from features\n",
        "    X_train_dir_i = np.delete(train_dir_ds_i.features, protected_index, axis=1)\n",
        "    X_test_dir_i = np.delete(test_dir_ds_i.features, protected_index, axis=1)\n",
        "\n",
        "    #train LightGBM model on the repaired daataset\n",
        "    lgb_dir_model_i = lgb.LGBMClassifier(\n",
        "        random_state=rand, max_depth=5, num_leaves=33, verbose=-1, **lgb_params\n",
        "    )\n",
        "    lgb_dir_model_i.fit(X_train_dir_i, train_dir_ds_i.labels)\n",
        "\n",
        "    # predict on the repaired dataset\n",
        "    test_dir_ds_pred_i = test_dir_ds_i.copy()\n",
        "    test_dir_ds_pred_i.labels = lgb_dir_model_i.predict(X_test_dir_i)\n",
        "\n",
        "    # fairness metrics\n",
        "    metrics_test_dir_ds = BinaryLabelDatasetMetric(\n",
        "        test_dir_ds_pred_i,\n",
        "        unprivileged_groups=unprivileged_groups,\n",
        "        privileged_groups=privileged_groups\n",
        "    )\n",
        "    di_i = metrics_test_dir_ds.disparate_impact()\n",
        "\n",
        "    # track and print DI for this level\n",
        "    print(F\"Repair Level: {level:.2f}, Disparate Impact: {di_i:.4f}\")\n",
        "\n",
        "    #update thebest results if this level is closest to DI=1\n",
        "    if (di.shape[0] == 0) or (np.min(np.abs(di -1)) >= abs(di_i -1)):\n",
        "        train_dir_ds = train_dir_ds_i\n",
        "        test_dir_ds = test_dir_ds_i\n",
        "        X_train_dir = X_train_dir_i\n",
        "        X_test_dir = X_test_dir_i\n",
        "        lgb_dir_model = lgb_dir_model_i\n",
        "\n",
        "    # append to DI List\n",
        "    di = np.append(di, di_i)"
      ],
      "metadata": {
        "id": "9oYBaebjxeFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Disparate Impact across repair levels\n",
        "di = di[:len(levels)]"
      ],
      "metadata": {
        "id": "lWNlKS-_xjj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close(plt.gcf())"
      ],
      "metadata": {
        "id": "cyX7iBA_xnWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Seaborn style for better visuals\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(11, 6))"
      ],
      "metadata": {
        "id": "KQ5Dup46xrak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Disparate Impact (DI) against repair levels\n",
        "plt.plot(levels, di, marker=\"o\", linestyle=\"-\", color=\"blue\", label=\"Disparate Impact\")"
      ],
      "metadata": {
        "id": "Aojm4vx4xujU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add labels, title, and legend\n",
        "plt.ylabel(\"Disparate Impact (DI)\", fontsize=14)\n",
        "plt.xlabel(\"Repair Level\", fontsize=14)\n",
        "plt.title(\"Disparate Impact Across Repair Levels\", fontsize=16)\n",
        "plt.legend(fontsize=12)"
      ],
      "metadata": {
        "id": "17IZm0MQxydG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show grid for readability\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "BPVDZBBwx2Al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "f2EC6R48x6zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "display(plt.gcf())"
      ],
      "metadata": {
        "id": "ROKgHsRUx960"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the best repair level and its corresponding disparate impact\n",
        "best_level = levels[np.argmin(np.abs(di - 1))]\n",
        "print(f\"Best Repair Level: {best_level:.2f}\")\n",
        "print(f\"Disparate Impact at Best Level: {di[np.argmin(np.abs(di - 1))]:.4f}\")"
      ],
      "metadata": {
        "id": "u59DaJ5KyB5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1.1b."
      ],
      "metadata": {
        "id": "H6-qVzEcyG7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Coarser granularity\n",
        "levels = np.hstack([np.linspace(0., 0.1, 10), np.linspace(0.2, 1, 5)])\n",
        "protected_index = train_ds.feature_names.index(\"Age_Group\")"
      ],
      "metadata": {
        "id": "qwOng7gpyE81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize variables to track the best repair level\n",
        "di = np.array([])  # Collect Disparate Impact for all levels\n",
        "train_dir_ds = None\n",
        "test_dir_ds = None\n",
        "X_train_dir = None\n",
        "X_test_dir = None\n",
        "lgb_dir_model = None"
      ],
      "metadata": {
        "id": "KhKylSLyyPDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop through repair levels\n",
        "for level in tqdm(levels):\n",
        "    #apply DIR at the current repair level\n",
        "    di_remover = DisparateImpactRemover(repair_level=level)\n",
        "    train_dir_ds_i = di_remover.fit_transform(train_ds)\n",
        "    test_dir_ds_i = di_remover.fit_transform(test_ds)\n",
        "\n",
        "    #remove protected attribute from features\n",
        "    X_train_dir_i = np.delete(train_dir_ds_i.features, protected_index, axis=1)\n",
        "    X_test_dir_i = np.delete(test_dir_ds_i.features, protected_index, axis=1)\n",
        "\n",
        "    #train LightGBM model on the repaired daataset\n",
        "    lgb_dir_model_i = lgb.LGBMClassifier(\n",
        "        random_state=rand, max_depth=5, num_leaves=33, verbose=-1, **lgb_params\n",
        "    )\n",
        "    lgb_dir_model_i.fit(X_train_dir_i, train_dir_ds_i.labels)\n",
        "\n",
        "    # predict on the repaired dataset\n",
        "    test_dir_ds_pred_i = test_dir_ds_i.copy()\n",
        "    test_dir_ds_pred_i.labels = lgb_dir_model_i.predict(X_test_dir_i)\n",
        "\n",
        "    # fairness metrics\n",
        "    metrics_test_dir_ds = BinaryLabelDatasetMetric(\n",
        "        test_dir_ds_pred_i,\n",
        "        unprivileged_groups=unprivileged_groups,\n",
        "        privileged_groups=privileged_groups\n",
        "    )\n",
        "    di_i = metrics_test_dir_ds.disparate_impact()\n",
        "\n",
        "    # track and print DI for this level\n",
        "    print(F\"Repair Level: {level:.2f}, Disparate Impact: {di_i:.4f}\")\n",
        "\n",
        "    #update thebest results if this level is closest to DI=1\n",
        "    if (di.shape[0] == 0) or (np.min(np.abs(di -1)) >= abs(di_i -1)):\n",
        "        train_dir_ds = train_dir_ds_i\n",
        "        test_dir_ds = test_dir_ds_i\n",
        "        X_train_dir = X_train_dir_i\n",
        "        X_test_dir = X_test_dir_i\n",
        "        lgb_dir_model = lgb_dir_model_i\n",
        "\n",
        "    # append to DI List\n",
        "    di = np.append(di, di_i)"
      ],
      "metadata": {
        "id": "XG89QPKWyR5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Disparate Impact across repair levels\n",
        "di = di[:len(levels)]"
      ],
      "metadata": {
        "id": "xQiZtFgtyXbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close(plt.gcf())"
      ],
      "metadata": {
        "id": "7xSjJJbqyYxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Seaborn style for better visuals\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "plt.figure(figsize=(11, 6))"
      ],
      "metadata": {
        "id": "E0wX1K8LycIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the Disparate Impact (DI) against repair levels\n",
        "plt.plot(levels, di, marker=\"^\", linestyle=\"-\", color=\"red\", label=\"Disparate Impact\")"
      ],
      "metadata": {
        "id": "2QmFu4rOyetM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add labels, title, and legend\n",
        "plt.ylabel(\"Disparate Impact (DI)\", fontsize=14)\n",
        "plt.xlabel(\"Repair Level\", fontsize=14)\n",
        "plt.title(\"Disparate Impact Across Repair Levels\", fontsize=16)\n",
        "plt.legend(fontsize=12)"
      ],
      "metadata": {
        "id": "-varKQpnyh3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show grid for readability\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "fIXlf40Oyl8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l9yPzFNCyoZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "display(plt.gcf())"
      ],
      "metadata": {
        "id": "B-tzWshkyrFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the best repair level and its corresponding disparate impact\n",
        "best_level = levels[np.argmin(np.abs(di - 1))]\n",
        "print(f\"Best Repair Level: {best_level:.2f}\")\n",
        "print(f\"Disparate Impact at Best Level: {di[np.argmin(np.abs(di - 1))]:.4f}\")"
      ],
      "metadata": {
        "id": "r2yMiEx-yuNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1.2): Identify the best repair level and the Disparate Impact at the best repair level."
      ],
      "metadata": {
        "id": "_2N6v3BTyyhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the original data: DI= 0.865 at Repair Level 0.5.  For fine granuality: DI % RL where the same.  For coarse granulity: DI= 0.868 @ RL 0.4.  So the\n",
        "Coarse setting seemed to do best.  All inputs had the sam Zpattern.  The finer the levls, the more activity at the low repair level of 0.1.  At this\n",
        "Level DI varied from 0.82 to 0.85.  For all 3 tests, with over 90% of the DI levels above 80%, bias does not seem like problem for this data set."
      ],
      "metadata": {
        "id": "iQzQ2E1my3WN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1.3): Retrain a Light GBM model on the modified DIR data with the best repair level and\n",
        "compute both the performance metrics and the fairness metrics."
      ],
      "metadata": {
        "id": "Nvw2nkOcy7jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train LightGbM\n",
        "lgb_dir_model = LGBMClassifier(\n",
        "    random_state=531,\n",
        "    max_depth=6,\n",
        "    num_leaves=33,\n",
        "    **lgb_params\n",
        ")"
      ],
      "metadata": {
        "id": "Saqmx2Zry_98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use reweighted dataset's instance weights\n",
        "lgb_dir_model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    sample_weight=train_dir_ds.instance_weights\n",
        ")"
      ],
      "metadata": {
        "id": "CL6xnyMizDrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate performance metrics\n",
        "y_pred_test_dir = lgb_dir_model.predict(X_test)\n",
        "y_pred_prob_test_dir = lgb_dir_model.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "zJaH8ZmSzH-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Performance Metrics\n",
        "accuracy_dir = accuracy_score(y_test, y_pred_test_dir)\n",
        "precision_dir = precision_score(y_test, y_pred_test_dir)\n",
        "recall_dir = recall_score(y_test, y_pred_test_dir)\n",
        "f1_dir = f1_score(y_test, y_pred_test_dir)\n",
        "roc_auc_dir = roc_auc_score(y_test, y_pred_prob_test_dir)"
      ],
      "metadata": {
        "id": "JJCUfT6xzLpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPerformance Metrics for DIR Model:\")\n",
        "print(f\"Accuracy: {accuracy_dir:.4f}\")\n",
        "print(f\"Precision: {precision_dir:.4f}\")\n",
        "print(f\"Recall: {recall_dir:.4f}\")\n",
        "print(f\"F1-Score: {f1_dir:.4f}\")\n",
        "print(f\"ROC-AUC: {roc_auc_dir:.4f}\")"
      ],
      "metadata": {
        "id": "KmXE4prpzOSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment: 82% accuracy is OK, Correct Positve Prediction of 65% is fair.  Recall of 54% (correct positives is poor.  \n",
        "F1 00.59 shows a moderate balance between Precision and Recall.  Strong ROC at 0.8, showing model ability to distiguish\n",
        "positive versus negative cases."
      ],
      "metadata": {
        "id": "SMTFCp_HzU7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Fairness Metrics\n",
        "test_pred_dir_ds = test_ds.copy(deepcopy=True)\n",
        "test_pred_dir_ds.labels = y_pred_test_dir.reshape(-1, 1)\n",
        "test_pred_dir_ds.scores = y_pred_prob_test_dir.reshape(-1,1)"
      ],
      "metadata": {
        "id": "losv0V1izRgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fairness Metrics for the DIR Model\n",
        "metrics_test_dir_cls = ClassificationMetric(\n",
        "    test_ds,\n",
        "    test_pred_dir_ds,\n",
        "    unprivileged_groups=unprivileged_groups,\n",
        "    privileged_groups=privileged_groups\n",
        ")"
      ],
      "metadata": {
        "id": "6XLBAA1EzcP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Fairness Metrics\n",
        "print(\"\\nFairness Metrics for DIR Model:\")\n",
        "print(f\"Statistical Parity Difference (SPD): {metrics_test_dir_cls.statistical_parity_difference():.4f}\")\n",
        "print(f\"Disparate Impact (DI): {metrics_test_dir_cls.disparate_impact():.4f}\")\n",
        "print(f\"Equal Opportunity Difference (EOD): {metrics_test_dir_cls.equal_opportunity_difference():.4f}\")\n",
        "print(f\"Average Odds Difference (AOD): {metrics_test_dir_cls.average_odds_difference():.4f}\")\n",
        "print(f\"Differential Fairness Bias Amplification (DFBA): {metrics_test_dir_cls.differential_fairness_bias_amplification():.4f}\")"
      ],
      "metadata": {
        "id": "zUnmOq5Gzfnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comment: SPD of -0.14 shows moderate unfairness against yhe underprivileged group.  DI of 0.84 is within acceptable range.  \n",
        "EOD of -0.04 shows small bias against underpriviledged group.  AOD of -0.1 shows obvious bias against underprivileged group.\n",
        "DFBA of 0.25 indicates some bias amplification."
      ],
      "metadata": {
        "id": "ChWXMxRPzjus"
      }
    }
  ]
}